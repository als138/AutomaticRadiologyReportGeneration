# Automatic Radiology Report Generation using RAG and LLMs

A full end-to-end pipeline for automatic generation of CT scan reports using Visionâ€“Language Models (VLMs) and Large Language Models (LLMs), with a RAG (Retrievalâ€‘Augmented Generation) architecture to boost accuracy via a local knowledge base.

---

## ğŸ—ï¸ Project Architecture

The system consists of two main stages:

1. **Image Analysis**  
   A VLM (e.g. LLaVA) processes the CT scan image and outputs preliminary findings in text.

2. **RAGâ€‘Enhanced Report Generation**  
   Preliminary findings are augmented with similar reports retrieved from a local FAISS knowledge base, and fed into an LLM (e.g. Gemma) to generate a structured final report.

**Pipeline Flow:**

```
[CT Image] â†’ [LLaVA Vision Model] â†’ [Preliminary Findings (Text)]
               â†“                                â†“
      [RAG Retriever: FAISS] â†’ â†’ â†’ â†’ â†’ â†’ â†’ â†’ [Gemma LLM] â†’ [Final Report]
```

---

## ğŸ” Features

- **Endâ€‘toâ€‘End Pipeline**: From image input to structured text output  
- **Local Execution**: Full operation locally to preserve privacy  
- **RAGâ€‘Based**: Retrieves similar historical reports to increase accuracy and coherence  
- **Highly Customizable**: Swap LLM, VLM, or embedding models to fit your needs

---

## âš™ï¸ Technology Stack

- **LLM**: `google/gemma-7b-it` (or `google/gemma-2b`)  
- **VLM**: `llavaâ€‘hf/llavaâ€‘1.5â€‘7bâ€‘hf`  
- **Embedding Model**: `pritamdeka/Sâ€‘BioBertâ€‘snliâ€‘multinliâ€‘stsb`  
- **Vector DB**: FAISS (Facebook AI Similarity Search)  
- **Frameworks**: LangChain, Transformers, PyTorch

---

## ğŸš€ Setup and Installation

### 1. Prerequisites

- Python 3.10+  
- Git  
- NVIDIA GPU (min. 16â€¯GB VRAM; 24â€¯GB recommended)

### 2. Clone the Repository

```bash
git clone <YOURâ€‘REPOSITORYâ€‘URL>
cd <YOURâ€‘PROJECTâ€‘DIRECTORY>
```

### 3. Directory Structure

Ensure your project root matches the following layout:

```
/
|-- data_reports/       # All .txt medical report files
|-- test_images/        # Sample CT scan images
|-- vector_store/       # Directory where FAISS stores vectors
|-- 1_prepare_knowledge_base.py
|-- 2_generate_report.py
â””-- README.md
```

### 4. Install Dependencies

Use a virtual environment:

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate

pip install -r requirements.txt
```

**requirements.txt** should include:

```
torch
torchvision
torchaudio
langchain
langchain-community
transformers
sentence-transformers
faiss-cpu    # or faiss-gpu if on Linux
bitsandbytes
accelerate
pypdf
unstructured
Pillow
```

---

## ğŸ¯ How to Use

### 1. Prepare Data  
Place anonymized `.txt` medical report files into `data_reports/`.

### 2. Hugging Face Authentication  

```bash
huggingface-cli login
```

Accept terms for:

- `google/gemma-7b-it`  
- `llavaâ€‘hf/llavaâ€‘1.5â€‘7bâ€‘hf`

### 3. Build the Knowledge Base  

```bash
python 1_prepare_knowledge_base.py
```

### 4. Generate a Report  

- Place a CT scan sample (e.g. `sample.jpg`) into `test_images/`  
- Update `TEST_IMAGE_PATH` in `2_generate_report.py`  
- Run:

```bash
python 2_generate_report.py
```

The final report will appear in the console.

---

## âš™ï¸ Configuration

Update the following parameters at the top of `2_generate_report.py`:

- `LLM_MODEL_ID`  
- `VLM_MODEL_ID`  
- `TEST_IMAGE_PATH`

---

## âš ï¸ Disclaimer

This project is strictly a research Proof of Concept.  
**The generated reports MUST be reviewed and verified by a qualified human radiologist.**  
Do not use outputs for clinical diagnosis or medical decisions.

---

## ğŸ“ License

This project is licensed under the **MIT License**.  
See the `LICENSE` file in the repository for more details.

---

## â„¹ï¸ Further Customization

- Add **Usage Examples** (include sample inputs and expected outputs)  
- Include **Badge Icons** (e.g. CI status, test coverage, version) at the top  
- Add sections like **Contribution Guidelines** or **Code of Conduct**

